% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[10pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
\geometry{margin=1in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{listings} % For showing code
\usepackage{lmodern}
\usepackage{indentfirst}
\usepackage{microtype}

\lstset{
  basicstyle=\ttfamily,
  keywordstyle=\color{blue}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  commentstyle=\color{green}\ttfamily,
  morecomment=[l][\color{magenta}]{\#},
  columns=fullflexible,
  showstringspaces=false,
  %frame=single,
  breaklines=true,
  postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
}


%%% END Article customizations

%%% The "real" document content comes below...

\title{Short Summary of GRIFFIN Data Analysis}
\author{Kurtis Raymond}
\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 

\begin{document}
\maketitle

\section{Overview}

The analysis of data provided by the GRIFFIN array is done using a ROOT based program called GRSISort.
The source code for GRSISort is written in C++ and contains many classes to assist with the analysis of data from a nuclear spectroscopic experiment.
This guide is intended to help analyists to produce human readable sprectrums using GRSISort.

Generally, data analysis will take the following form,
\begin{enumerate}
\item
Sorting the MIDAS data produced from the experiment and producing fragment trees and analysis trees (stored in .root files)
\item
Applying corrections to data.
This includes:
\begin{enumerate}
\item
Linear Gain Matching
\item
Cross Talk
\item
Non-linear gain matching (aka Residuals)
\end{enumerate}
\item
Producing a final .root file that contains histograms and matricies for analysizing spectra
\end{enumerate}

\subsection{Conventions used in this doccument}

When a snippit of code begins with the \texttt{\$} character ismeans to run it in a shell prompt, or coded into a bash script. Lines begining with \texttt{GRSI []} are intended to be used with GRSISort's CLang interpriter, and similarly can be used in \texttt{.cxx} scripts.
Files that end in \texttt{.cxx} should have a compiled portion can be called by \texttt{\$ <name>}.

\subsection{Unpacking into GRSISort}

\begin{enumerate}
\item
(Optional) Download and Compile ROOT and GRSISort using scripts contained in \texttt{setup\_scripts}

\item
Copy all files from \texttt{src\_scripts} that are not shared by GRSISort into \texttt{GRSISort/scripts}

\item
Place calibration runs into \texttt{runs\_cal} and exprimental runs into \texttt{runs\_data}

\item
Copy any exsiting calibration data into \texttt{calibrations}

\end{enumerate}

\section{Creating Calibration Files}

\subsection{First sort of data}
The midas files corrisponding to the calibration runs (usually the first runs done in an experiment) need to be sorted first.

\begin{lstlisting}[language=c++]
$  grsisort -laq -suppress-errors -is-correcting-cross-talk -sort-depth=70000000 /dir/to/midas/file
\end{lstlisting}

See the GRSISort wiki for an explanation of the flags used above.

If there is an already existing \texttt{.cal} file with rough gain match coefficencents (ie. on a $^{60}$Co source), we can apply it in the above method by appending the appropirate \texttt{.cal} file to the command above.

\subsection{Applying a strict linear gain match}

This step is important for setting up the next corrections.
Using \texttt{kLinearGainMatch.cxx} we need to gain match two of our strongest peaks.
These will become our base-line points for generating the energy residuals.
Line 60 need to be changed to reflect the energy of the gamma rays used for calibration.

Afterwords, examine the energy calibration matrix to ensure the peaks used for calibration have the same energy.
This can be acomplished using something such as:

\begin{lstlisting}[language=c++]
GRSI [] AnalysisTree->Draw("TGriffin.fGriffinLowGainHits.GetEnergy():TGriffin.fGriffinLowGainHits.GetChannel().fNumber>>h(64,0,64,4000,0,4000)","TSceptar.GetMultiplicity()>0","colz")
\end{lstlisting}

To get a more comprehesive overview, \texttt{kMakeCalMatricies.cxx} can be used to generate a \texttt{.root} file containing other diagnostic histograms and matricies.

\subsection{Calculating Residuals}

For this step we will use the script \texttt{kResidualCalculator.cxx}.
This scripts takes any number of calibration peaks to calculate what the true response is of the DAQ system.
Energies should be selected from well known literature values, and the more peaks used for this calibration, the better.
The energies should be hard coded into lines 105 and 121.
This script will spit out a \texttt{residuals.root} file that contains the \texttt{TGraph} files that need to imported into our runtime scripts.

The \texttt{.root} file will contain a \texttt{TCanvas} object that shows a summary of each crystal.
To access the residuals, and how to use them will be explained later in this doccument.


\subsection{Cross Talk Corrections \protect\footnote{Addopted from Kevin Ortner} }

Now that we have nicely callibrated energies, we can now compute our CT coefficents that will be stored in a \texttt{.cal} file.
We will then use this calibration file when we resort our data.
To compute the coefficents, we will use a selector class which uses the two prominent transitions from ${^{60}}$Co.
These files are normally excituted using a command in bash such as,
\begin{lstlisting}[language=c++]
 $ grsiproof  {rootfile}.root /path/to/selector.C
 \end{lstlisting}
This command will generate a file called  \lstinline{ct_coefficients.cal}, we then input this file into \texttt{GriffinCTFix.cxx} through the following method:
\begin{lstlisting}[language=c++]
 $ GriffinCTFix CrossTalk.root <name>.cal
  \end{lstlisting}
Which spits out a cal file containing the CT coefficents called \texttt{<name>.cal}. We can ether load this file manually into our \texttt{.root} using,
\begin{lstlisting}[language=c++]
 GRSI [] TChannel::ReadCalFile("ct_correction.cal")
 GRSI [] TChannel::WriteToRoot()
\end{lstlisting}
Otherwise, we can modifiy the last lines of the main function \texttt{GriffinCTFix.cxx} with the above.

\section{Applying Corrections to Analysis}

Now that all the calibration data has been calculated, it needs to be applied to the rest of the data.

\subsection{Sorting the run data}

Much like the calibration data, the data needs to be sorted from the midas files.
This time, all the calibration files should prexist.
Much like before:

\begin{lstlisting}[language=c++]
$  grsisort <flags> <midas files> ct_correction.cal <linear gain match>.cal
\end{lstlisting}


\subsection{Residuals}

To use the residuals we calculated previously we can use a code snippit such as,
\begin{lstlisting}[language=c++,numbers=left, xleftmargin=5.0ex,caption=Example residual code for loading residuals]
    if( gFile->cd("Energy_Residuals") ) {
        printf("Energy residual calibration data found. Loading...\n");

        TGraph* TempResidual;
        for( int i = 1 ; i <= 64 ; i++ ) {
            gDirectory->GetObject(Form("Graph;%d",i), TempResidual);
            pGriff->LoadEnergyResidual( i-1, TempResidual);
        }
        gFile->cd(); // Return to the top directory
        printf("Done.\n");
\end{lstlisting}
Some explinations of the above,
\begin{description}
\item [gFile]
This pointer points to the current file opened. This needs to be changed to the variable that points to the \texttt{residuals.root} file.
\item [gDirectory]
Similar to gFile, this points to the current directory inside the root file.
\item [pGriff]
Pointer to TGriffin inside the \texttt{<data>.root} file
\end{description}
For examples of use, see included scripts like \texttt{LeanMatricies.cxx} in which the script has been split up into two sections of code.
One within the outer main function, and then within the inner main function, and the residuals are stored in a \texttt{TGraph} vector.
When working with selector scripts, the code snippit has been placed in the \texttt{InitializeBranches} member function of the selector class, within the corrisponding \texttt{.h} file.

There are now two methods of constructing the analysis matricies that will be used put the data into a human readable form.

\begin{enumerate}
\item  \texttt{kLeanMatricies.cxx}
\item Selector script
\end{enumerate}

Both methods are based on the same process. To use kLeanMatricies use the following command,

\begin{lstlisting}{language=bash}
$ kLeanMatricies.cxx <analysis.root> residuals.root
\end{lstlisting}

\end{document}
